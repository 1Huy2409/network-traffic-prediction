# ğŸ“Š Prediction Dashboard Guide

## ğŸ¯ Giá»›i thiá»‡u

Dashboard trá»±c quan hiá»ƒn thá»‹ káº¿t quáº£ prediction real-time tá»« AI models (VAE + LSTM) cho network traffic utilization.

## âœ¨ TÃ­nh nÄƒng

### 1. **Real-time Monitoring**

- ğŸ”´ Live status cá»§a prediction service
- ğŸ“Š Utilization trend chart (last 20 predictions)
- ğŸ¯ Model comparison (VAE vs LSTM)
- ğŸ“‹ Predictions history table

### 2. **Visualizations**

- **Line Chart**: Trend cá»§a VAE, LSTM, Average qua thá»i gian
- **Bar Chart**: So sÃ¡nh output cá»§a 2 models cho prediction má»›i nháº¥t
- **Status Indicators**: Color-coded status (LOW/MEDIUM/HIGH)

### 3. **Auto-update**

- **WebSocket mode**: Real-time updates khi cÃ³ prediction má»›i (náº¿u Node.js backend Ä‘ang cháº¡y)
- **Polling mode**: Tá»± Ä‘á»™ng refresh má»—i 3 giÃ¢y (fallback)

---

## ğŸš€ CÃ¡ch sá»­ dá»¥ng

### BÆ°á»›c 1: Start Prediction Service

```bash
cd D:\HuyCoding\PBL4\PBL4-Network-Traffic-Prediction
python prediction_service.py --port 5000
```

Hoáº·c dÃ¹ng script:

```bash
./start-prediction-service.bat
```

### BÆ°á»›c 2: Start Docker Containers

```bash
cd D:\HuyCoding\PBL4\SAGSINs-System\docker
docker-compose up -d
```

### BÆ°á»›c 3: Start Node.js Backend

```bash
cd D:\HuyCoding\PBL4\SAGSINs-System\wep-app\backend
npm start
```

### BÆ°á»›c 4: Start Frontend (Web App)

```bash
cd D:\HuyCoding\PBL4\SAGSINs-System\wep-app\frontend
npm run dev
```

### BÆ°á»›c 5: Má»Ÿ Dashboard

CÃ³ 2 cÃ¡ch:

#### Option 1: Truy cáº­p qua Prediction Service

```
http://localhost:5000
```

#### Option 2: Má»Ÿ file trá»±c tiáº¿p

```
Má»Ÿ file: D:\HuyCoding\PBL4\PBL4-Network-Traffic-Prediction\dashboard.html
```

---

## ğŸ“¡ Kiáº¿n trÃºc Dataflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web App    â”‚ (Frontend - React)
â”‚   Port 5173  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Socket.IO
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Node.js    â”‚ (Backend - Socket.IO)
â”‚   Port 3001  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTP POST
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Docker     â”‚ (Flask Server)
â”‚   Port 8080  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTP POST
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Prediction  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚  Dashboard   â”‚
â”‚  Service     â”‚ Serve   â”‚  (HTML/JS)   â”‚
â”‚  Port 5000   â”‚         â”‚  Port 5000   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†‘
       â”‚ WebSocket (Real-time updates)
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Node.js    â”‚
â”‚   Backend    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow khi gá»­i packet:

1. **User** gá»­i packet tá»« Web App (React)
2. **Node.js Backend** nháº­n qua Socket.IO
3. **Docker Server** táº¡o traffic metrics vÃ  lÆ°u CSV
4. **Prediction Service** Ä‘Æ°á»£c gá»i bá»Ÿi Docker server
5. **AI Models** (VAE + LSTM) predict utilization
6. **Docker Server** tráº£ prediction vá» Node.js
7. **Node.js** broadcast prediction qua WebSocket
8. **Dashboard** nháº­n vÃ  update charts real-time

---

## ğŸ¨ Dashboard Components

### Status Cards

- **Service Status**: Online/Offline/Unhealthy
- **Latest Prediction**: Average utilization (%)
- **Active Link**: Link ID Ä‘ang Ä‘Æ°á»£c predict
- **Total Predictions**: Tá»•ng sá»‘ predictions Ä‘Ã£ táº¡o

### Charts

1. **Utilization Trend** (Line Chart)

   - X-axis: Thá»i gian
   - Y-axis: Utilization (%)
   - 3 lines: VAE (blue), LSTM (pink), Average (cyan)
   - Keep last 20 predictions

2. **Model Comparison** (Bar Chart)
   - So sÃ¡nh output cá»§a VAE vs LSTM vs Average
   - Update má»—i khi cÃ³ prediction má»›i

### Predictions Table

- **Columns**: Timestamp, Link ID, VAE, LSTM, Average, Status
- **Status Badge**:
  - ğŸŸ¢ LOW: < 60%
  - ğŸŸ¡ MEDIUM: 60-80%
  - ğŸ”´ HIGH: > 80%
- Show 10 recent predictions (newest first)

---

## ğŸ”§ API Endpoints

### Prediction Service (Port 5000)

#### 1. `GET /`

Dashboard UI (HTML page)

#### 2. `GET /api`

API information

```json
{
  "service": "PBL4 Prediction Service",
  "version": "1.0.0",
  "status": "running"
}
```

#### 3. `POST /predict`

Run prediction

```bash
curl -X POST http://localhost:5000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "csv_path": "D:/HuyCoding/PBL4/SAGSINs-System/docker/data/traffic_data.csv",
    "use_latest": true
  }'
```

Response:

```json
{
  "status": "success",
  "prediction": {
    "link_id": "LINK_AIR_GROUND_01",
    "timestamp": "2025-11-15T16:10:57.793",
    "vae": {
      "utilization": 0.5642,
      "utilization_percent": 56.42,
      "status": "LOW"
    },
    "lstm": {
      "utilization": 0.2816,
      "utilization_percent": 28.16,
      "status": "LOW"
    },
    "average": {
      "utilization": 0.4229,
      "utilization_percent": 42.29,
      "status": "LOW"
    }
  }
}
```

#### 4. `GET /predictions?limit=50`

Get recent predictions

```bash
curl http://localhost:5000/predictions?limit=20
```

Response:

```json
{
  "status": "success",
  "total": 100,
  "returned": 20,
  "predictions": [...]
}
```

#### 5. `GET /health`

Health check

```bash
curl http://localhost:5000/health
```

Response:

```json
{
  "status": "healthy",
  "predictor": "loaded",
  "models": {
    "vae": true,
    "lstm": true
  },
  "total_predictions": 42
}
```

---

## ğŸ§ª Testing

### Test 1: Health Check

```bash
curl http://localhost:5000/health
```

Expected: `"status": "healthy"`

### Test 2: Send Packet tá»« Web App

1. Má»Ÿ Web App: http://localhost:5173
2. Register node: `UAV_01`
3. Send packet: `UAV_01` â†’ `GROUND_GATEWAY_01`
4. Check logs:
   - Node.js: `âœ… Traffic data saved`
   - Prediction service: `[SUCCESS] Prediction complete`
   - Dashboard: Chart tá»± Ä‘á»™ng update

### Test 3: View Dashboard

1. Má»Ÿ: http://localhost:5000
2. Kiá»ƒm tra:
   - âœ… Service Status = "Online"
   - âœ… Charts hiá»ƒn thá»‹ data
   - âœ… Table cÃ³ predictions
   - âœ… Real-time updates khi gá»­i packet má»›i

---

## ğŸ› Troubleshooting

### Dashboard khÃ´ng load

**Triá»‡u chá»©ng**: Blank page hoáº·c 404  
**NguyÃªn nhÃ¢n**: `dashboard.html` khÃ´ng Ä‘Æ°á»£c serve  
**Giáº£i phÃ¡p**:

```bash
# Äáº£m báº£o dashboard.html cÃ¹ng folder vá»›i prediction_service.py
ls D:\HuyCoding\PBL4\PBL4-Network-Traffic-Prediction\dashboard.html

# Restart prediction service
python prediction_service.py --port 5000
```

### Service Status = "Offline"

**Triá»‡u chá»©ng**: Red indicator, "Offline" status  
**NguyÃªn nhÃ¢n**: Prediction service khÃ´ng cháº¡y  
**Giáº£i phÃ¡p**:

```bash
cd D:\HuyCoding\PBL4\PBL4-Network-Traffic-Prediction
python prediction_service.py --port 5000
```

### Charts khÃ´ng update

**Triá»‡u chá»©ng**: Data cÅ©, khÃ´ng cÃ³ real-time updates  
**NguyÃªn nhÃ¢n**: WebSocket khÃ´ng káº¿t ná»‘i  
**Giáº£i phÃ¡p**:

```bash
# Check Node.js backend Ä‘ang cháº¡y
curl http://localhost:3001/nodes

# Náº¿u khÃ´ng cháº¡y:
cd D:\HuyCoding\PBL4\SAGSINs-System\wep-app\backend
npm start
```

**Fallback**: Dashboard tá»± Ä‘á»™ng polling má»—i 3 giÃ¢y náº¿u WebSocket fail

### Predictions = 0

**Triá»‡u chá»©ng**: "No predictions yet"  
**NguyÃªn nhÃ¢n**: ChÆ°a gá»­i packet  
**Giáº£i phÃ¡p**: Gá»­i Ã­t nháº¥t 1 packet tá»« Web App

---

## ğŸ“š Technology Stack

- **Frontend**: Vanilla JavaScript, HTML5, CSS3
- **Charts**: Chart.js 4.4.0
- **Real-time**: Socket.IO 4.5.4
- **Backend**: FastAPI (Python 3.13)
- **AI Models**: PyTorch (VAE + LSTM)

---

## ğŸ“ Demo Scenario

```
Scenario: Monitor network congestion cho UAV â†’ Ground link

1. User má»Ÿ Dashboard (http://localhost:5000)
   â†’ Status: Online, 0 predictions

2. User gá»­i large packet (10KB) tá»« Web App
   UAV_01 â†’ GROUND_GATEWAY_01

3. Docker server:
   âœ… Generate traffic metrics
   âœ… Save to CSV
   âœ… Call prediction service

4. AI Models predict:
   ğŸ“Š VAE:  73.2%
   ğŸ“Š LSTM: 74.5%
   ğŸ“Š AVG:  73.8% (MEDIUM)

5. Dashboard auto-updates:
   âœ… Status card shows 73.8%
   âœ… Line chart adds new point
   âœ… Bar chart updates
   âœ… Table adds new row with ğŸŸ¡ MEDIUM badge

6. User continues sending packets
   â†’ Dashboard tracks trend over time
   â†’ Alert náº¿u utilization > 80% (HIGH)
```

---

## ğŸš€ Next Steps

### Enhancements:

- [ ] Alert notifications khi HIGH utilization
- [ ] Export predictions to CSV/JSON
- [ ] Historical charts (last 24 hours)
- [ ] Per-link filtering
- [ ] Dark mode theme
- [ ] Mobile responsive design
- [ ] Authentication/login

### Integration:

- [ ] Prometheus metrics export
- [ ] Grafana dashboard
- [ ] Email/SMS alerts
- [ ] Database persistence (PostgreSQL)

---

**ğŸ¯ Enjoy monitoring your network predictions!** ğŸš€
